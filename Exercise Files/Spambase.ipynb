{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAMBASE DATASET\n",
    "\n",
    "**File:** Spambase.ipynb\n",
    "\n",
    "**Course:** Data Science Foundations: Data Mining in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                   # For dataframes\n",
    "import matplotlib.pyplot as plt                       # For plotting data\n",
    "import seaborn as sns                                 # For plotting data\n",
    "from sklearn.model_selection import train_test_split  # For train/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD AND PREPARE DATA\n",
    "Many of the datasets for this course come from the Machine Learning Repository at the University of California, Irvine (UCI) at [https://archive.ics.uci.edu/](https://archive.ics.uci.edu/).\n",
    "\n",
    "For all the three demonstrations of clustering techniques, we'll use the `Spambase Data Set`, which can be accessed via [https://archive.ics.uci.edu/ml/datasets/Spambase](https://archive.ics.uci.edu/ml/datasets/Spambase). We'll use the dataset saved in the file `spambase.data`. \n",
    "\n",
    "This data can be downloaded as a `CSV` file without the variable names using `pd.read_csv`. You'll need to manually add the `.csv` extension. This code saves the file in the data folder of our Python directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To read read the dataset from a local CSV file, run the following cell. (This is the recommended approach.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/spambase_raw.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alternatively, to read the data from the UCI ML Repository, uncomment the lines in the cell below and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\n",
    "#     'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data',\n",
    "#     header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Variables\n",
    "\n",
    "- Assign a name to all attributes as `X0`, `X1`, ..., `X56`.\n",
    "- Assign `y` to the class variable (the last column of df).\n",
    "- Display the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequentially renames all attribute columns and renames the last column to 'y'\n",
    "df.columns = ['X' + str(i) for i in range(0, len(df.columns) - 1)] + ['y']\n",
    "\n",
    "# Shows the first few lines of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data\n",
    "To prepare the dataset for classification, we have to split it into train and test sets.\n",
    "\n",
    "- `train_test_split()` splits the data into train and test.\n",
    "- In the arguments list, the data matrix consists of all attribute columns. Extract columns `X0`, `X1`, ..., `X56` with `df.filter(regex='\\d')`. The filter keeps only the names that have a numeric character in them.\n",
    "- Specify the target variable as `df.y`.\n",
    "- Set up `trn` and `tst` dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies X by filtering all columns with a number in name\n",
    "X_trn, X_tst, y_trn, y_tst = train_test_split(\n",
    "    df.filter(regex='\\d'),  \n",
    "    df.y, \n",
    "    test_size=0.30,\n",
    "    random_state=1)\n",
    "\n",
    "# Creates the training dataset, trn\n",
    "trn = X_trn\n",
    "trn['y'] = y_trn\n",
    "\n",
    "# Creates the testing dataset, tst\n",
    "tst = X_tst\n",
    "tst['y'] = y_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORE TRAINING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Plot of Class Variable\n",
    "\n",
    "Use Seaborn's `countplot()` function to create a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='y', data=trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Attribute Variables\n",
    "Select four arbitrary features and get paired plots (takes a moment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a grid using Seaborn's PairGrid()\n",
    "g = sns.PairGrid(\n",
    "    trn, \n",
    "    vars=['X5', 'X20', 'X25', 'X53'], \n",
    "    hue='y', \n",
    "    diag_sharey=False, \n",
    "    palette=['red', 'green'])\n",
    "\n",
    "# Adds histograms on the diagonal\n",
    "g.map_diag(plt.hist)\n",
    "\n",
    "# Adds density plots above the diagonal\n",
    "g.map_upper(sns.kdeplot)\n",
    "\n",
    "# Adds scatterplots below the diagonal\n",
    "g.map_lower(sns.scatterplot)\n",
    "\n",
    "# Adds a legend\n",
    "g.add_legend(title='Spam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE DATA\n",
    "Save `df`, `trn`, and `tst` to CSV files to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/spambase.csv', sep=',', index=False)\n",
    "trn.to_csv('data/spambase_trn.csv', sep=',', index=False)\n",
    "tst.to_csv('data/spambase_tst.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN UP\n",
    "\n",
    "- If desired, clear the results with Cell > All Output > Clear. \n",
    "- Save your work by selecting File > Save and Checkpoint.\n",
    "- Shut down the Python kernel and close the file by selecting File > Close and Halt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
