{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSOCIATION ANALYSIS WITH FP-GROWTH\n",
    "\n",
    "**File:** FPGrowth.ipynb\n",
    "\n",
    "**Course:** Data Science Foundations: Data Mining in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALL AND IMPORT PACKAGES\n",
    "The Python package `mlxtend` contains the implementation of the FP-growth algorithm, which can be installed with Python's `pip` command. This command only needs to be done once per machine.\n",
    "\n",
    "The standard, shorter approach may work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above command didn't work, it may be necessary to be more explicit, in which case you could run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once `mlxtend` is installed, then load the packages below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                   # For dataframes\n",
    "import matplotlib.pyplot as plt                       # For plotting data\n",
    "from mlxtend.preprocessing import TransactionEncoder  # For FP-tree algorithm\n",
    "from mlxtend.frequent_patterns import fpgrowth        # For FP-tree algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD AND PREPARE DATA\n",
    "For this demonstration, we'll use the dataset `Groceries.csv`, which comes from the R package `arules` and is saved as a CSV file. The data is in transactional format (as opposed to tabular format), which means that each row is a list of items purchased together and that the items may be in different order. There are 32 columns in each row, each column either contains a purchased items or NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "- To read read the dataset from a local CSV file, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = []\n",
    "\n",
    "with open('data/Groceries.csv') as f:\n",
    "    for line in f:\n",
    "        transaction = [item for item in line.strip().split(',') if item != 'NaN']\n",
    "        transactions.append(transaction)\n",
    "    \n",
    "transactions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY FP-GROWTH\n",
    "\n",
    "## Prepare Data\n",
    "\n",
    "- Create a \"wide\" dataframe where each column corresponds to a single good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Rules\n",
    "\n",
    "- Call `fpgrowth()` on `transactions`. \n",
    "- As parameters `fpgrowth()` can take the minimum support ratio and minimum confidence. \n",
    "- Only the pairs of items that satisfy these criteria would be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_df = fpgrowth(df, min_support=0.01, use_colnames=True, max_len=2, verbose=False)\n",
    "\n",
    "rules_df = rules_df[rules_df.itemsets.map(len) == 2]\n",
    "rules_df['From'] = rules_df['itemsets'].map(lambda x: list(x)[0])\n",
    "rules_df['To'] = rules_df['itemsets'].map(lambda x: list(x)[1])\n",
    "rules_df['N'] = (rules_df['support'] * len(transactions)).astype(int)\n",
    "\n",
    "rules_df.sort_values('N', ascending=False, inplace=True)\n",
    "\n",
    "rules_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Rules with N's\n",
    "- The code below calls `plot()` on each row of the rules DataFrame to create a list of all the mined rules. \n",
    "- First, we have to add two numeric columns corresponding to each item to `rules_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick top rules\n",
    "rules_df = rules_df.sort_values('N', ascending=False).head(50)\n",
    "\n",
    "# List of all items\n",
    "items = set(rules_df['From']) | set(rules_df['To'])\n",
    "\n",
    "# Creates a mapping of items to numbers\n",
    "imap = {item : i for i, item in enumerate(items)}\n",
    "\n",
    "# Maps the items to numbers and adds the numeric 'FromN' and 'ToN' columns\n",
    "rules_df['FromN'] = rules_df['From'].map(imap)\n",
    "rules_df['ToN'] = rules_df['To'].map(imap)\n",
    "\n",
    "# Displays the top 20 association rules, sorted by Support\n",
    "rules_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Rules\n",
    "Plot each pair of items in the rule. If a rule is A->B, then the item A is in the bottom row of the plot (y=0) and B is in the top row (y=1). The color of each line indicates the support of the rule multiplied by 10 (support*10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds ticks to the top of the graph also\n",
    "plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = True\n",
    "\n",
    "# Sets the size of the plot\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Draws a line between items for each rule\n",
    "# Colors each line according to the support of the rule\n",
    "for index, row in rules_df.head(20).iterrows():\n",
    "    plt.plot([row['FromN'], row['ToN']], [0, 1], 'o-',\n",
    "             c=plt.cm.viridis(row['support'] * 10),\n",
    "             markersize=20)\n",
    "\n",
    "# Adds a colorbar and its title  \n",
    "cb = plt.colorbar(plt.cm.ScalarMappable(cmap='viridis'))\n",
    "cb.set_label('Support*10')\n",
    "\n",
    "# Adds labels to xticks and removes yticks\n",
    "plt.xticks(range(len(items)), items, rotation='vertical')\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN UP\n",
    "\n",
    "- If desired, clear the results with Cell > All Output > Clear. \n",
    "- Save your work by selecting File > Save and Checkpoint.\n",
    "- Shut down the Python kernel and close the file by selecting File > Close and Halt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
