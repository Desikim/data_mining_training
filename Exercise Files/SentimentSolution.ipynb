{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT SCORING SOLUTION\n",
    "\n",
    "**File:** SentimentSolution.ipynb\n",
    "\n",
    "**Course:** Data Science Foundations: Data Mining in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHALLENGE\n",
    "\n",
    "In this challenge, I invite you to to do the following:\n",
    "\n",
    "1. Import the text `LittleWomen.txt` by Louisa May Alcott from the data folder (this text is downloaded from Project Gutenberg at https://www.gutenberg.org/ebooks/514.)\n",
    "1. Add section numbers for sections of 100 lines.\n",
    "1. Tokenize the data.\n",
    "1. Score the sentiments.\n",
    "1. Calculate average sentiment scores for each section of 100 lines.\n",
    "1. Graph the \"sentiment arc\" of the story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re  # For regular expressions\n",
    "import nltk  # For text functions\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "import pandas as pd  # For dataframes\n",
    "from afinn import Afinn  # For sentiment values\n",
    "\n",
    "# Import corpora and functions from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download data for NLTK\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('opinion_lexicon', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# Use Matplotlib style sheet\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/LittleWomen.txt',sep='\\t')\\\n",
    "    .dropna()\\\n",
    "    .drop('gutenberg_id', 1)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATA\n",
    "\n",
    "\n",
    "## Add Line Numbers\n",
    "\n",
    "- These numbers will be used to divide the text into sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['line'] = range(1, len(df) + 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert all text to lowercase\n",
    "    text = text.replace(\"'\", '')\n",
    "    text = re.sub(r'[^\\w]', ' ', text)  # Leave only word characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Omit extra space characters\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].map(clean_text) \n",
    "df['text'] = df['text'].map(word_tokenize) # Split text into word tokens\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Tokens into a Single Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('text')\\\n",
    "    .rename(columns={'text': 'token'})\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORE SENTIMENTS\n",
    "\n",
    "- Calculate sentiment scores using the AFINN lexicon, which scores words on a scale of -5 (most negative) to +5 (most positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_scorer = Afinn()\n",
    "\n",
    "df['score'] = df['token'].map(afinn_scorer.score).astype(int)\n",
    "df = df[df['score'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show a frequency table for the sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_freq = df.score.value_counts().sort_index().to_frame('n')\n",
    "\n",
    "score_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Score Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_freq.plot.bar(\n",
    "    legend=False,\n",
    "    figsize=(8, 4),\n",
    "    grid=True,\n",
    "    color='gray')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency of Words')\n",
    "plt.title('The Iliad: Sentiment Scores by Words', loc='left')\n",
    "plt.xticks(rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT ARC\n",
    "\n",
    "- Divide the text into sections of 100 lines and calculate a sentiment score for each section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_acc = df.groupby(df['line'] // 100)\\\n",
    "    .score.mean()\\\n",
    "    .to_frame('score')\\\n",
    "    .rename_axis('section')\n",
    "\n",
    "score_acc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Scores by Section to View Narrative Arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = score_acc.plot.line(legend=False, figsize=(12, 6), grid=True, alpha=0.5, color='gray')\n",
    "score_acc.rolling(10, min_periods=5).mean().plot.line(ax=ax, color='black')\n",
    "plt.xlabel('Section of 100 Lines')\n",
    "plt.ylabel('Mean Sentiment Score')\n",
    "plt.title('Little Women: Mean Sentiment Score by Section', loc='left')\n",
    "plt.axhline(0, color='red')\n",
    "plt.xticks(rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN UP\n",
    "\n",
    "- If desired, clear the results with Cell > All Output > Clear. \n",
    "- Save your work by selecting File > Save and Checkpoint.\n",
    "- Shut down the Python kernel and close the file by selecting File > Close and Halt."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
